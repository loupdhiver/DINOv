{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from dinov.BaseModel import BaseModel\n",
    "from dinov import build_model\n",
    "from utils.arguments import load_opt_from_config_file\n",
    "\n",
    "from demo import task_openset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageMask(gr.components.Image):\n",
    "    \"\"\"\n",
    "    Sets: source=\"canvas\", tool=\"sketch\"\n",
    "    \"\"\"\n",
    "\n",
    "    is_template = True\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(source=\"upload\", tool=\"sketch\", interactive=True, **kwargs)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        return super().preprocess(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build args\n",
    "'''\n",
    "# args = parse_option()\n",
    "\n",
    "ckpt = '/data/experimentation/dinov/model_swinL.pth'\n",
    "\n",
    "'''\n",
    "build model\n",
    "'''\n",
    "\n",
    "sam_cfg= '/app/configs/dinov_sam_coco_swinl_train.yaml'\n",
    "\n",
    "opt = load_opt_from_config_file(sam_cfg)\n",
    "\n",
    "model_sam = BaseModel(opt, build_model(opt)).from_pretrained(ckpt).eval().cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                   generic_vp5, generic_vp6, generic_vp7, generic_vp8, image2, **kwargs):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        model=model_sam\n",
    "        a= task_openset(model, generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                   generic_vp5, generic_vp6, generic_vp7, generic_vp8, image2, **kwargs)\n",
    "        return a\n",
    "\n",
    "\n",
    "'''\n",
    "launch app\n",
    "'''\n",
    "title = \"DINOv: Visual In-Context Prompting\"\n",
    "\n",
    "article = \"The Demo is Run on DINOv.\"\n",
    "\n",
    "demo = gr.Blocks()\n",
    "image_tgt=gr.components.Image(label=\"Target Image \",type=\"pil\",brush_radius=15.0)\n",
    "gallery_output=gr.components.Image(label=\"Results Image \",type=\"pil\",brush_radius=15.0)\n",
    "\n",
    "generic_vp1 = ImageMask(label=\"scribble on refer Image 1\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp2 = ImageMask(label=\"scribble on refer Image 2\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp3 = ImageMask(label=\"scribble on refer Image 3\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp4 = ImageMask(label=\"scribble on refer Image 5\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp5 = ImageMask(label=\"scribble on refer Image 6\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp6 = ImageMask(label=\"scribble on refer Image 7\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp7 = ImageMask(label=\"scribble on refer Image 8\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp8 = ImageMask(label=\"scribble on refer Image 9\",type=\"pil\",brush_radius=15.0)\n",
    "generic = gr.TabbedInterface([\n",
    "                        generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                        generic_vp5, generic_vp6, generic_vp7, generic_vp8\n",
    "                    ], [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"])\n",
    "\n",
    "title='''\n",
    "# DINOv: Visual In-Context Prompting\n",
    "\n",
    "# [[Read our arXiv Paper](https://arxiv.org/pdf/2311.13601.pdf)\\] &nbsp; \\[[Github page](https://github.com/UX-Decoder/DINOv)\\] \n",
    "'''\n",
    "\n",
    "with demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3.0):\n",
    "            generation_tittle = gr.Markdown(title)\n",
    "            image_tgt.render()\n",
    "            generic.render()\n",
    "            with gr.Row(scale=2.0):\n",
    "                clearBtn = gr.ClearButton(\n",
    "                    components=[image_tgt])\n",
    "                runBtn = gr.Button(\"Run\")\n",
    "        with gr.Column(scale=5.0):\n",
    "\n",
    "            gallery_tittle = gr.Markdown(\"# Open-set results.\")\n",
    "            with gr.Row(scale=9.0):\n",
    "                gallery_output.render()\n",
    "\n",
    "            example = gr.Examples(\n",
    "                examples=[\n",
    "                    [\"demo/examples/bags.jpg\"],\n",
    "                    [\"demo/examples/img.png\"],\n",
    "                    [\"demo/examples/corgi2.jpg\"],\n",
    "                    [\"demo/examples/ref_cat.jpeg\"],\n",
    "                ],\n",
    "                inputs=image_tgt,\n",
    "                cache_examples=False,\n",
    "            )\n",
    "\n",
    "    title = title,\n",
    "    article = article,\n",
    "    allow_flagging = 'never',\n",
    "\n",
    "    runBtn.click(inference, inputs=[generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                    generic_vp5, generic_vp6, generic_vp7, generic_vp8, image_tgt],\n",
    "                outputs = [gallery_output])\n",
    "\n",
    "\n",
    "\n",
    "demo.queue().launch()'''\n",
    "build args\n",
    "'''\n",
    "# args = parse_option()\n",
    "\n",
    "ckpt = '/data/experimentation/dinov/model_swinL.pth'\n",
    "\n",
    "'''\n",
    "build model\n",
    "'''\n",
    "\n",
    "sam_cfg= '/app/configs/dinov_sam_coco_swinl_train.yaml'\n",
    "\n",
    "opt = load_opt_from_config_file(sam_cfg)\n",
    "\n",
    "model_sam = BaseModel(opt, build_model(opt)).from_pretrained(ckpt).eval().cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                   generic_vp5, generic_vp6, generic_vp7, generic_vp8, image2, **kwargs):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        model=model_sam\n",
    "        a= task_openset(model, generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                   generic_vp5, generic_vp6, generic_vp7, generic_vp8, image2, **kwargs)\n",
    "        return a\n",
    "\n",
    "\n",
    "'''\n",
    "launch app\n",
    "'''\n",
    "title = \"DINOv: Visual In-Context Prompting\"\n",
    "\n",
    "article = \"The Demo is Run on DINOv.\"\n",
    "\n",
    "demo = gr.Blocks()\n",
    "image_tgt=gr.components.Image(label=\"Target Image \",type=\"pil\",brush_radius=15.0)\n",
    "gallery_output=gr.components.Image(label=\"Results Image \",type=\"pil\",brush_radius=15.0)\n",
    "\n",
    "generic_vp1 = ImageMask(label=\"scribble on refer Image 1\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp2 = ImageMask(label=\"scribble on refer Image 2\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp3 = ImageMask(label=\"scribble on refer Image 3\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp4 = ImageMask(label=\"scribble on refer Image 5\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp5 = ImageMask(label=\"scribble on refer Image 6\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp6 = ImageMask(label=\"scribble on refer Image 7\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp7 = ImageMask(label=\"scribble on refer Image 8\",type=\"pil\",brush_radius=15.0)\n",
    "generic_vp8 = ImageMask(label=\"scribble on refer Image 9\",type=\"pil\",brush_radius=15.0)\n",
    "generic = gr.TabbedInterface([\n",
    "                        generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                        generic_vp5, generic_vp6, generic_vp7, generic_vp8\n",
    "                    ], [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"])\n",
    "\n",
    "title='''\n",
    "# DINOv: Visual In-Context Prompting\n",
    "\n",
    "# [[Read our arXiv Paper](https://arxiv.org/pdf/2311.13601.pdf)\\] &nbsp; \\[[Github page](https://github.com/UX-Decoder/DINOv)\\] \n",
    "'''\n",
    "\n",
    "with demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3.0):\n",
    "            generation_tittle = gr.Markdown(title)\n",
    "            image_tgt.render()\n",
    "            generic.render()\n",
    "            with gr.Row(scale=2.0):\n",
    "                clearBtn = gr.ClearButton(\n",
    "                    components=[image_tgt])\n",
    "                runBtn = gr.Button(\"Run\")\n",
    "        with gr.Column(scale=5.0):\n",
    "\n",
    "            gallery_tittle = gr.Markdown(\"# Open-set results.\")\n",
    "            with gr.Row(scale=9.0):\n",
    "                gallery_output.render()\n",
    "\n",
    "            example = gr.Examples(\n",
    "                examples=[\n",
    "                    [\"demo/examples/bags.jpg\"],\n",
    "                    [\"demo/examples/img.png\"],\n",
    "                    [\"demo/examples/corgi2.jpg\"],\n",
    "                    [\"demo/examples/ref_cat.jpeg\"],\n",
    "                ],\n",
    "                inputs=image_tgt,\n",
    "                cache_examples=False,\n",
    "            )\n",
    "\n",
    "    title = title,\n",
    "    article = article,\n",
    "    allow_flagging = 'never',\n",
    "\n",
    "    runBtn.click(inference, inputs=[generic_vp1, generic_vp2, generic_vp3, generic_vp4,\n",
    "                    generic_vp5, generic_vp6, generic_vp7, generic_vp8, image_tgt],\n",
    "                outputs = [gallery_output])\n",
    "\n",
    "\n",
    "\n",
    "demo.queue().launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
